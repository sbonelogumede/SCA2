[
  {
    "objectID": "q5.html",
    "href": "q5.html",
    "title": "Question 5",
    "section": "",
    "text": "coresNumber = detectCores()\nmyCluster &lt;- makeCluster(coresNumber - 1)\nregisterDoParallel(myCluster)\n\n# Generate 3 vectors of size 5 from the normal distribution\nnormalVector &lt;- irnorm(n = 5, mean = 0, sd = 1, count = 3)\nclusterExport(myCluster, c(\"normalVector\", \"nextElem\"))\n\nf.foreach &lt;- function()\n{\n    maximumVector &lt;&lt;- foreach(i = 1:3, .combine = \"c\") %dopar% \n        {\n            max(nextElem(normalVector)) # Get the next vector and find its maximum\n        }\n}\n\nf.parLapply &lt;- function()\n{\n    maximumVector &lt;&lt;- parLapply(myCluster, 1:3, function(i)\n    {\n        max(nextElem(normalVector)) # Get the next vector and find its maximum\n    })\n}\n\nf.replicate &lt;- function()\n{\n    maximumVector &lt;&lt;- replicate(n = 3, expr = max(nextElem(normalVector)))\n}\n\nkable(x = system.time(f.foreach()), col.names = c(\"Metric\", \"foreach\"))\n\n\n\n\nMetric\nforeach\n\n\n\n\nuser.self\n0.00\n\n\nsys.self\n0.00\n\n\nelapsed\n0.03\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\nkable(x = system.time(f.parLapply()), col.names = c(\"Metric\", \"parLapply\"))\n\n\n\n\nMetric\nparLapply\n\n\n\n\nuser.self\n0.02\n\n\nsys.self\n0.00\n\n\nelapsed\n0.00\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\nkable(x = system.time(f.replicate()), col.names = c(\"Metric\", \"replicate\"))\n\n\n\n\nMetric\nreplicate\n\n\n\n\nuser.self\n0\n\n\nsys.self\n0\n\n\nelapsed\n0\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\nstopCluster(myCluster)"
  },
  {
    "objectID": "q3.html",
    "href": "q3.html",
    "title": "Question 3",
    "section": "",
    "text": "N &lt;- 50  # Sample size\ntrue_mean &lt;- 1  # True population mean\nB &lt;- 1000  # Number of bootstrap samples\ncount &lt;- 0  # Count the number of confidence intervals that capture the true mean\n\nfor (i in 1:B) {\n    dat &lt;- rexp(N, rate = 1)  # Simulate new sample\n    boot_means &lt;- replicate(B, mean(sample(dat, N, replace = TRUE)))  # Bootstrap resampling\n    \n    \n    ci &lt;- quantile(boot_means, c(0.025, 0.975)) # 95% percentile confidence interval\n    \n    # Check if the true mean is within the CI\n    if (ci[1] &lt;= true_mean & true_mean &lt;= ci[2]) {\n        count &lt;- count + 1\n    }\n}\n\ncoverage &lt;- (count / B) * 100 # Calculate estimated coverage\nkable(x = coverage, col.names = c(\"Coverage %\"))\n\n\n\n\nCoverage %\n\n\n\n\n91.2"
  },
  {
    "objectID": "q1.html",
    "href": "q1.html",
    "title": "Question 1",
    "section": "",
    "text": "results &lt;- foreach(i=1:100, .combine=\"rbind\") %do% \n    {\n        S &lt;- rexp(n = 100, rate = 1)\n        c(mean(S), var(S))\n    }\n\ncolnames(results) &lt;- c(\"Mean\", \"Variance\")\nrownames(results) &lt;- 1:100\nkable(results)\n\n\n\n\nMean\nVariance\n\n\n\n\n1.0827506\n0.9965731\n\n\n0.8453451\n0.6882944\n\n\n1.0419317\n0.8723723\n\n\n1.1308284\n1.4440074\n\n\n1.0396586\n0.9116125\n\n\n1.0726473\n1.2284185\n\n\n1.0527143\n1.2666333\n\n\n0.9547942\n0.8055204\n\n\n1.0029685\n1.2951649\n\n\n0.8606381\n0.5718827\n\n\n0.8736713\n0.6781141\n\n\n1.1475118\n1.2947726\n\n\n0.9608615\n1.1744800\n\n\n1.2942995\n1.3577474\n\n\n0.9740392\n0.7593594\n\n\n1.2064476\n1.8878306\n\n\n1.0416930\n0.9714231\n\n\n0.9357591\n0.8040410\n\n\n0.9223724\n1.0927168\n\n\n0.9348340\n0.9639536\n\n\n1.3266091\n2.6592767\n\n\n1.0516408\n1.1884297\n\n\n1.0806904\n1.2964386\n\n\n0.8598242\n0.7181621\n\n\n0.9884458\n0.6992367\n\n\n0.9784197\n0.9136894\n\n\n0.9335910\n0.7679833\n\n\n0.9270676\n1.0486034\n\n\n1.1304755\n1.1991698\n\n\n1.1062578\n1.4644122\n\n\n0.9528994\n0.7575913\n\n\n1.0432925\n0.8474089\n\n\n0.9882566\n1.2540334\n\n\n0.9585885\n0.9654003\n\n\n0.9671749\n0.8200149\n\n\n0.8983244\n0.7523789\n\n\n0.9151576\n0.8905351\n\n\n1.1282054\n0.9317209\n\n\n0.9810045\n1.1913243\n\n\n1.0311976\n0.9584290\n\n\n1.0825813\n0.9217099\n\n\n1.0526187\n0.9413473\n\n\n0.9532645\n0.8951161\n\n\n0.9425200\n1.1694731\n\n\n1.0044959\n0.9981196\n\n\n0.9048681\n0.7591322\n\n\n0.9343599\n1.1232216\n\n\n1.0771285\n0.9120452\n\n\n0.9937348\n0.8532903\n\n\n1.0180863\n1.0992419\n\n\n1.0595693\n1.1177769\n\n\n0.9067712\n0.5365624\n\n\n1.1630579\n1.3839023\n\n\n1.0349644\n0.9170299\n\n\n0.8930765\n0.6687058\n\n\n0.9722632\n0.6846369\n\n\n1.0756503\n0.9508061\n\n\n0.9870721\n0.9610708\n\n\n1.0814501\n1.0957361\n\n\n0.8411033\n0.7027457\n\n\n0.8909359\n0.7760849\n\n\n0.9242116\n0.8022308\n\n\n1.0447007\n1.5649353\n\n\n0.7873329\n0.5242584\n\n\n1.3142775\n1.4283362\n\n\n1.0361609\n1.1461439\n\n\n0.7639876\n0.4594847\n\n\n0.9488380\n0.7793831\n\n\n0.8822508\n0.8101314\n\n\n0.9415935\n0.8042258\n\n\n1.1548067\n1.2775756\n\n\n1.0895655\n1.1269586\n\n\n1.0046116\n0.8055513\n\n\n0.9885617\n0.9236318\n\n\n0.9835089\n0.8890867\n\n\n0.8248409\n0.6249320\n\n\n1.1779427\n1.1503257\n\n\n0.9298873\n0.7381086\n\n\n0.8875968\n0.8475602\n\n\n1.0950911\n1.1126847\n\n\n1.0132051\n0.7812125\n\n\n0.9584936\n1.1870641\n\n\n0.9905348\n0.7213548\n\n\n0.9663419\n0.8174452\n\n\n0.9485220\n0.9452582\n\n\n0.9596900\n0.6125321\n\n\n1.1149441\n1.0923087\n\n\n0.9289375\n0.7405039\n\n\n1.0463454\n1.3476912\n\n\n1.0418395\n0.9648890\n\n\n0.9959590\n1.0887518\n\n\n0.9397903\n0.9562129\n\n\n1.1213649\n1.4112124\n\n\n0.9261270\n0.7980945\n\n\n0.9765410\n1.0068409\n\n\n1.2153660\n1.7587396\n\n\n0.9870923\n1.1868369\n\n\n1.0658846\n1.1474115\n\n\n1.1377639\n1.3050966\n\n\n0.9552085\n0.9041848"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Assignment 2",
    "section": "",
    "text": "This is the homepage for assignment 2.\nTo find the code for this assignment visit https://github.com/sbonelogumede/SCA2.git.\n\n\n\n\n\n\nFigureÂ 1: Data Visualization (Google DeepMind)."
  },
  {
    "objectID": "q2.html",
    "href": "q2.html",
    "title": "Question 2",
    "section": "",
    "text": "library(doParallel)\nlibrary(foreach)\nlibrary(knitr)\nlibrary(MASS)\n\ncoreNumber &lt;- detectCores() # Get number of cores in the computing device\nmyCluster &lt;- makeCluster(round((coreNumber / 2))) # Set round n/2 of those cores for computing\nregisterDoParallel(myCluster) # Register these cores for computing\n\ndat &lt;- galaxies # Galaxies data set from the MASS library\n\nclusterExport(myCluster, \"dat\") # Copy the data across the allocated cores\n\nf.foreach &lt;- function(N) # Parallel bootstrapping\n{\n    Vector &lt;- foreach(i = 1:N, .combine = \"c\") %dopar% \n        {\n            S &lt;- sample(x = dat, size = length(dat), replace = TRUE)\n            median(x = S) # Find the median for this bootstrap sample\n        }\n    return(Vector)\n}\n\nf.for &lt;- function(N) # Serial bootstrapping\n{   Vector &lt;- numeric(N)\n    for(i in 1:N)\n    {\n        S &lt;- sample(x = dat, size = length(dat), replace = TRUE)\n        Vector[i] &lt;- median(x = S)\n    }\n    return(Vector)\n}\n\n\nkable(x = system.time(f.foreach(N = 1000)), col.names = c(\"Metric\", \"Parallel Performance\"))\n\n\n\n\nMetric\nParallel Performance\n\n\n\n\nuser.self\n0.18\n\n\nsys.self\n0.03\n\n\nelapsed\n0.25\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\nkable(x = system.time(f.for(N = 1000)), col.names = c(\"Metric\", \"Serial Performance\"))\n\n\n\n\nMetric\nSerial Performance\n\n\n\n\nuser.self\n0.03\n\n\nsys.self\n0.00\n\n\nelapsed\n0.03\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\n\nProcessing time for parallel computing exceeds processing time for serial computing. This is because the problem is too small. The total time for serial execution is smaller than that of first allocating workers, then completing this task in parallel. We expect parallel performance to improve as the problem gets very large because then the time taken to run the problem serially would exceed the time taken to execute the problem in parallel. Let N = 100 000\n\nkable(x = system.time(f.foreach(N = 100000)), col.names = c(\"Metric\", \"Parallel Performance\"))\n\n\n\n\nMetric\nParallel Performance\n\n\n\n\nuser.self\n15.80\n\n\nsys.self\n3.14\n\n\nelapsed\n19.34\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\nkable(x = system.time(f.for(N = 100000)), col.names = c(\"Metric\", \"Serial Performance\"))\n\n\n\n\nMetric\nSerial Performance\n\n\n\n\nuser.self\n3.37\n\n\nsys.self\n0.05\n\n\nelapsed\n3.45\n\n\nuser.child\nNA\n\n\nsys.child\nNA\n\n\n\n\n\nNo improvement in parallel performance. This is likely because of the overhead of allocating workers to different cores and concatenating the results.\n\n# Bias\nmedianVector &lt;- f.for(N = 1000)\nsampleMedian &lt;- median(x = dat)\nkable(x = sampleMedian, col.names = c(\"Sample Median\"))\n\n\n\n\nSample Median\n\n\n\n\n20833.5\n\n\n\n\nbootstrapMedian &lt;- mean(x = medianVector)\nkable(x = bootstrapMedian, col.names = c(\"Bootstrap Median Estimate\"))\n\n\n\n\nBootstrap Median Estimate\n\n\n\n\n20879.31\n\n\n\n\nbias &lt;- bootstrapMedian - sampleMedian\nkable(x = bias, col.names = c(\"Bias Estimate\"))\n\n\n\n\nBias Estimate\n\n\n\n\n45.811\n\n\n\n\n# Standard Error\nse &lt;- sd(medianVector)\nkable(x = se, col.names = c(\"Standard Error Estimate\"))\n\n\n\n\nStandard Error Estimate\n\n\n\n\n511.1805\n\n\n\n\n# 95% Percentile Confidence Interval\nci &lt;- quantile(x = medianVector, c(0.025, 0.975))\nkable(x = ci, col.names = c(\"95% Percentile Confidence Interval\"))\n\n\n\n\n\n95% Percentile Confidence Interval\n\n\n\n\n2.5%\n20174.94\n\n\n97.5%\n22072.50\n\n\n\n\nstopCluster(myCluster) # Close the cluster"
  },
  {
    "objectID": "q4.html",
    "href": "q4.html",
    "title": "Question 4",
    "section": "",
    "text": "set.seed(1234)\n\n# Generate 3 vectors of size 5 from the normal distribution\nnormalVector &lt;- irnorm(n = 5, mean = 0, sd = 1, count = 3)\n\nmaximumVector &lt;- foreach(i = 1:3, .combine = \"c\") %do% \n    {\n        max(nextElem(normalVector)) # Get the next vector and find its maximum\n    }\n\nkable(x = maximumVector, col.names = c(\"Column Maximums\"))\n\n\n\n\nColumn Maximums\n\n\n\n\n1.0844412\n\n\n0.5060559\n\n\n0.9594941"
  }
]